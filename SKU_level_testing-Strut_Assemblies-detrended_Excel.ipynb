{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865543d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "from plotnine import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import signal\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose, STL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a59aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6df7e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Strut_Assemblies_Python.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59034e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d507fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day'] = \"1\"\n",
    "df['Year']=df['Year'].astype(str)\n",
    "df['Month_Num']=df['Month_Num'].astype(str)\n",
    "# df['Month1']=df['Month_Num']\n",
    "# df['Year_Month']=pd.to_datetime(df[[\"Year\", \"Month\", \"Day\"]])\n",
    "df['Year_Month']=pd.to_datetime(df.Year+df.Month_Num+df.Day, format=\"%Y%m%d\")\n",
    "df.rename(columns={'Price':'Price'}, inplace=True)\n",
    "df.rename(columns={'Units':'Qty'}, inplace=True)\n",
    "df.rename(columns={'Part/Sku':'Material'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "421fccd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048573b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c0e0a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e10cd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna(axis=0, subset=('Price', ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ccedd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Price'] = df['Price'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3dccb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160ab047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Choose the top 80 SKU's\n",
    "# df=df[df['SKU Tag']=='Top 80%']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4647d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39143e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Check values in different PH2\n",
    "# category = df['PH2'].value_counts()\n",
    "# print(\"PH2 Category Percentage\\n{}\\n{}\\n PH2 Category values count\\n{}\\n{}\".format(\n",
    "#       50*\"-\", (category / len(df.index))[:5] * 100, 50*\"-\", category[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302dccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check values in different Life Cycle\n",
    "LC = df['LC'].value_counts()\n",
    "print(\"LC Percentage\\n{}\\n{}\\n LC values count\\n{}\\n{}\".format(\n",
    "      50*\"-\", (LC / len(df.index))[:5] * 100, 50*\"-\", LC[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a93ba06",
   "metadata": {},
   "source": [
    "## Without Exclusion of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5e7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate the data\n",
    "df_sku = df.groupby(['Year_Month','Material']).agg({'Price':'mean','Qty': 'mean' }).reset_index()\n",
    "# df_sku=df_sku[(df_sku.Year_Month<'2022-10-01') & (df_sku.Year_Month>='2020-07-01')]\n",
    "df_sku.head()\n",
    "\n",
    "# df_sku = df.groupby(['Year_Month','Material']).agg({'Sales':'sum','Qty': 'sum' }).reset_index()\n",
    "# df_sku['Price']=df_sku['Sales']/df_sku['Qty']\n",
    "# df_sku.head()\n",
    "# df_LC['Year_Month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7a57b2-d22f-4860-b3f1-ecf31685b06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_sku=df_sku.drop('Sales',axis=1)\n",
    "# df_sku.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f8df80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean, Max, Min by LCs\n",
    "prices = df_sku.groupby('Material').agg({'Price' : ['mean', 'min', 'max']})\n",
    "prices.columns = ['price_mean','price_min', 'price_max']\n",
    "prices[\"price_diff\"] = prices[\"price_max\"] - prices[\"price_min\"]\n",
    "prices = prices.reset_index()\n",
    "prices.sort_values(by=\"price_diff\", ascending = False, inplace = True)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
    "     print(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae6735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Box Plot\n",
    "# pct_threshold = 99.0\n",
    "# # censor below threshold\n",
    "# pct95facet = np.percentile(df_sku['Price'], pct_threshold)\n",
    "\n",
    "# box_dist = (\n",
    "#     ggplot(df_sku) + \n",
    "#     geom_boxplot(\n",
    "#         aes(x = 'LC',\n",
    "#             y = 'Price'), colour=\"#1F3552\", fill=\"#4271AE\", \n",
    "#                    alpha=0.7,\n",
    "#                    outlier_shape=\".\",\n",
    "#                    outlier_colour=\"red\"       \n",
    "#     ) +\n",
    "#     labs(\n",
    "#         title ='China Damper by LC',\n",
    "#         x = 'LC',\n",
    "#         y = 'Price',\n",
    "#     ) +\n",
    "#     scale_y_continuous() +\n",
    "#     geom_hline(yintercept = pct95facet) + # add percentile solid line\n",
    "#     theme(axis_text_x = element_text(angle = 45, hjust = 1)) + \n",
    "#     theme(figure_size=(20, 12)) + \n",
    "#     theme(text=element_text(family=\"Tahoma\", size=12)) +\n",
    "#     theme(axis_text_x=element_text(colour=\"black\", size=12)) +\n",
    "#     theme(axis_text_y=element_text(colour=\"black\", size=12))\n",
    "# )\n",
    "# box_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa36bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Prep using pivot\n",
    "x_pivot = df_sku.pivot(index= 'Year_Month' ,columns='Material' ,values='Price')\n",
    "x_values = pd.DataFrame(x_pivot.to_records())\n",
    "print(x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745b86b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing_x = x_values.isnull().sum() * 100 / len(x_values)\n",
    "missing_value_df_x = pd.DataFrame({'column_name': x_values.columns,\n",
    "                                 'percent_missing': percent_missing_x})\n",
    "missing_value_df_x.sort_values(by=['percent_missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0406a7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_missing_value_df_x=missing_value_df_x[missing_value_df_x.percent_missing<=20]\n",
    "mod_missing_value_df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51aa009",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_missing_value_df_x=mod_missing_value_df_x.reset_index(drop=True)\n",
    "mod_missing_value_df_x['column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5d8e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values_mod = x_values[x_values.columns[x_values.columns.isin(mod_missing_value_df_x['column_name'].astype('str'))]]\n",
    "x_values_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a09db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pivot = df_sku.pivot( index = 'Year_Month',columns='Material', values='Qty')\n",
    "y_values = pd.DataFrame(y_pivot.to_records())\n",
    "print(y_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c8d88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing_y = y_values.isnull().sum() * 100 / len(x_values)\n",
    "missing_value_df_y = pd.DataFrame({'column_name': y_values.columns,\n",
    "                                 'percent_missing': percent_missing_y})\n",
    "missing_value_df_y.sort_values(by=['percent_missing'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd1d2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_missing_value_df_y=missing_value_df_y[missing_value_df_y.percent_missing<=20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4591d744",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_missing_value_df_y=mod_missing_value_df_y.reset_index(drop=True)\n",
    "mod_missing_value_df_y['column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a72d953",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values_mod = y_values[y_values.columns[y_values.columns.isin(mod_missing_value_df_y['column_name'].astype('str'))]]\n",
    "y_values_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5675241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results_values_raw = { \"name\": [], \"price_elasticity\": [], \"price_mean\": [],\"quantity_mean\": [], \"intercept\": [],  \"t_score\":[], \"slope\": [], \"coefficient_pvalue\" : [], \"rsquared\" : []}\n",
    "results_values_detrended = { \"name\": [], \"price_elasticity\": [], \"price_mean\": [],\"quantity_mean\": [], \"intercept\": [],  \"t_score\":[], \"slope\": [], \"coefficient_pvalue\" : [], \"rsquared\" : []}\n",
    "results_values_deseasonalized = { \"name\": [], \"price_elasticity\": [], \"price_mean\": [],\"quantity_mean\": [], \"intercept\": [],  \"t_score\":[], \"slope\": [], \"coefficient_pvalue\" : [], \"rsquared\" : []}\n",
    "results_values_log_raw = { \"name\": [], \"price_elasticity\": [], \"price_mean\": [],\"quantity_mean\": [], \"intercept\": [],  \"t_score\":[], \"slope\": [], \"coefficient_pvalue\" : [], \"rsquared\" : []}\n",
    "results_values_log_detrended = { \"name\": [], \"price_elasticity\": [], \"price_mean\": [],\"quantity_mean\": [], \"intercept\": [],  \"t_score\":[], \"slope\": [], \"coefficient_pvalue\" : [], \"rsquared\" : []}\n",
    "results_values_log_deseasonalized = { \"name\": [], \"price_elasticity\": [], \"price_mean\": [],\"quantity_mean\": [], \"intercept\": [],  \"t_score\":[], \"slope\": [], \"coefficient_pvalue\" : [], \"rsquared\" : []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bdc042-0da9-44c6-af9e-426cef7b26ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in x_values_mod.columns[1:]:\n",
    "    column_points = []\n",
    "    for i in range(len(x_values_mod[column])):\n",
    "        if not np.isnan(x_values_mod[column][i]) and not np.isnan(y_values_mod[column][i]):\n",
    "            # column_points.append((x_values_mod['Year_Month'][i],x_values_mod[column][i], y_values_mod[column][i]))\n",
    "            column_points.append((i+1,x_values_mod['Year_Month'][i],x_values_mod[column][i], y_values_mod[column][i]))\n",
    "    # df = pd.DataFrame(list(column_points), columns= ['Date','x_value', 'y_value'])\n",
    "    df = pd.DataFrame(list(column_points), columns= ['Date_Index','Date','x_value', 'y_value'])\n",
    "    # print(df)\n",
    "    # sns.regplot(x=\"x_value\", y=\"y_value\", data=df, fit_reg=True)\n",
    "    # plt.xlabel('Price')\n",
    "    # plt.ylabel('Quantity')\n",
    "    # plt.title('Raw Price vs Raw Quantity')\n",
    "    # plt.show()\n",
    "    \n",
    "    #Slope\n",
    "    x_value = df['Date_Index']\n",
    "    y_value = df['y_value']\n",
    "    X = sm.add_constant(x_value)\n",
    "    model_x = sm.OLS(y_value, X)\n",
    "    result_x = model_x.fit()\n",
    "    intercept, slope = result_x.params\n",
    "    df['y_value_detrended'] = df['y_value'] - (df['Date_Index']*slope)\n",
    "    # print(df) \n",
    "    # sns.lineplot(data = df[['y_value','y_value_detrended']])\n",
    "    # plt.title('Detrended Plot')\n",
    "    # plt.show()\n",
    "    \n",
    "    # df.reset_index(inplace=False)\n",
    "    df = df.set_index('Date')\n",
    "    df.sort_index(inplace=True)\n",
    "    df = df.resample('MS').asfreq().fillna(0)\n",
    "    res = seasonal_decompose(df.y_value, extrapolate_trend='freq')\n",
    "    # df['y_value'] = res.trend\n",
    "    df['y_value_deseasonalized'] = df.y_value_detrended.values - res.seasonal\n",
    "    df = pd.DataFrame(df)\n",
    "    # print(df)\n",
    "    # sns.lineplot(data = df[['y_value','y_value_detrended','y_value_deseasonalized']])\n",
    "    # plt.title('Deseasonalized Plot')\n",
    "    # plt.show()\n",
    "    \n",
    "    # df['log_x_value'] = np.log(df['x_value'])\n",
    "    # df['log_y_value'] = np.log(df['y_value'])\n",
    "    # df['log_y_value_detrended'] = np.log(df['y_value_detrended'])\n",
    "    # df['log_y_value_deseasonalized'] = np.log(df['y_value_deseasonalized'])\n",
    "    \n",
    "    df['log_x_value'] = np.where(df['x_value'] > 0, np.log(df['x_value']) , 0)\n",
    "    df['log_y_value'] = np.where(df['y_value'] > 0, np.log(df['y_value']) , 0) \n",
    "    df['log_y_value_detrended'] = np.where(df['y_value_detrended'] > 0, np.log(df['y_value_detrended']) , 0)\n",
    "    df['log_y_value_deseasonalized'] = np.where(df['y_value_deseasonalized'] > 0, np.log(df['y_value_deseasonalized']) , 0)\n",
    "    # print(df)\n",
    "    \n",
    "    \n",
    "\n",
    "#     df.reset_index(inplace=False)\n",
    "#     df = df.set_index('Date')\n",
    "#     df_ts=df[['y_value']]\n",
    "#     # print(df_ts)\n",
    "#     sns.lineplot(data = df_ts)\n",
    "#     plt.title('Time Series of Raw Quantity')\n",
    "#     plt.show()\n",
    "#     # fig, ax = plt.subplots(figsize = (12,6))    \n",
    "#     # fig = sns.lineplot(x = \"Date\", y='y_value',data=df_ts,ax=ax)\n",
    "\n",
    "#     # df.reset_index(inplace=False)\n",
    "#     # df = df.set_index('Date')\n",
    "#     res = seasonal_decompose(df.y_value, extrapolate_trend='freq')\n",
    "#     # df['y_value'] = res.trend\n",
    "#     df['y_value'] = df.y_value.values - res.seasonal\n",
    "#     df = pd.DataFrame(df)\n",
    "#     print(df)\n",
    "#     sns.lineplot(data = df['y_value'])\n",
    "#     plt.title('Deseasonalized Time Series of Raw Quantity')\n",
    "#     plt.show()\n",
    "#     # df['y_value'] = df.y_value.values - res.trend\n",
    "    \n",
    "#     # res = STL(df_ts, robust = True).fit()\n",
    "#     # df_ts['y_value'] = df_ts['y_value'] - res.seasonal\n",
    "#     # df_ts = pd.DataFrame(df_ts)\n",
    "#     # print(df_ts)\n",
    "#     # sns.lineplot(data = df_ts[['y_value']])\n",
    "#     # plt.title('Deseasonalized Time Series of Raw Quantity')\n",
    "#     # plt.show()\n",
    "    \n",
    "    \n",
    "# #     df = pd.DataFrame(df)\n",
    "# #     print(df)\n",
    "# #     sns.lineplot(data = df[['y_value']])\n",
    "# #     plt.title('Deseasonalized Time Series of Raw Quantity')\n",
    "# #     plt.show()\n",
    "\n",
    "#     df=df.reset_index(drop=True)\n",
    "# #     df = df[(df.x_value < df.x_value.quantile(.95)) & (df.x_value > df.x_value.quantile(.05))]\n",
    "#     sns.regplot(x=\"x_value\", y=\"y_value\", data=df, fit_reg=True)\n",
    "#     plt.xlabel('Price')\n",
    "#     plt.ylabel('Quantity')\n",
    "#     plt.title('Raw Price vs Deseasonalized Quantity')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "    #Raw Model\n",
    "    x_value = df['x_value']\n",
    "    y_value = df['y_value']\n",
    "    X = sm.add_constant(x_value)\n",
    "    model = sm.OLS(y_value, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    #(Null Hypothesis test) Coefficient with a p value less than 0.05\n",
    "#     if result.f_pvalue < 0.05:\n",
    "        \n",
    "    rsquared = result.rsquared\n",
    "    coefficient_pvalue = result.f_pvalue\n",
    "    intercept, slope = result.params\n",
    "    mean_price = np.mean(x_value)\n",
    "    mean_quantity = np.mean(y_value)\n",
    "    tintercept, t_score = result.tvalues\n",
    "\n",
    "    #Price elasticity Formula\n",
    "    price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
    "\n",
    "    #Append results into dictionary for dataframe\n",
    "    results_values_raw[\"name\"].append(column)\n",
    "    results_values_raw[\"price_elasticity\"].append(price_elasticity)\n",
    "    results_values_raw[\"price_mean\"].append(mean_price)\n",
    "    results_values_raw[\"quantity_mean\"].append(mean_quantity)\n",
    "    results_values_raw[\"intercept\"].append(intercept)\n",
    "    results_values_raw['t_score'].append(t_score)\n",
    "    results_values_raw[\"slope\"].append(slope)\n",
    "    results_values_raw[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
    "    results_values_raw[\"rsquared\"].append(rsquared*100)\n",
    "    \n",
    "    #Detrended\n",
    "    x_value = df['x_value']\n",
    "    y_value = df['y_value_detrended']\n",
    "    X = sm.add_constant(x_value)\n",
    "    model = sm.OLS(y_value, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    #(Null Hypothesis test) Coefficient with a p value less than 0.05\n",
    "#     if result.f_pvalue < 0.05:\n",
    "        \n",
    "    rsquared = result.rsquared\n",
    "    coefficient_pvalue = result.f_pvalue\n",
    "    intercept, slope = result.params\n",
    "    mean_price = np.mean(x_value)\n",
    "    mean_quantity = np.mean(y_value)\n",
    "    tintercept, t_score = result.tvalues\n",
    "\n",
    "    #Price elasticity Formula\n",
    "    price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
    "\n",
    "    #Append results into dictionary for dataframe\n",
    "    results_values_detrended[\"name\"].append(column)\n",
    "    results_values_detrended[\"price_elasticity\"].append(price_elasticity)\n",
    "    results_values_detrended[\"price_mean\"].append(mean_price)\n",
    "    results_values_detrended[\"quantity_mean\"].append(mean_quantity)\n",
    "    results_values_detrended[\"intercept\"].append(intercept)\n",
    "    results_values_detrended['t_score'].append(t_score)\n",
    "    results_values_detrended[\"slope\"].append(slope)\n",
    "    results_values_detrended[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
    "    results_values_detrended[\"rsquared\"].append(rsquared*100)\n",
    "    \n",
    "    #Deseasonalized Model\n",
    "    x_value = df['x_value']\n",
    "    y_value = df['y_value_deseasonalized']\n",
    "    X = sm.add_constant(x_value)\n",
    "    model = sm.OLS(y_value, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    #(Null Hypothesis test) Coefficient with a p value less than 0.05\n",
    "#     if result.f_pvalue < 0.05:\n",
    "        \n",
    "    rsquared = result.rsquared\n",
    "    coefficient_pvalue = result.f_pvalue\n",
    "    intercept, slope = result.params\n",
    "    mean_price = np.mean(x_value)\n",
    "    mean_quantity = np.mean(y_value)\n",
    "    tintercept, t_score = result.tvalues\n",
    "\n",
    "    #Price elasticity Formula\n",
    "    price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
    "\n",
    "    #Append results into dictionary for dataframe\n",
    "    results_values_deseasonalized[\"name\"].append(column)\n",
    "    results_values_deseasonalized[\"price_elasticity\"].append(price_elasticity)\n",
    "    results_values_deseasonalized[\"price_mean\"].append(mean_price)\n",
    "    results_values_deseasonalized[\"quantity_mean\"].append(mean_quantity)\n",
    "    results_values_deseasonalized[\"intercept\"].append(intercept)\n",
    "    results_values_deseasonalized['t_score'].append(t_score)\n",
    "    results_values_deseasonalized[\"slope\"].append(slope)\n",
    "    results_values_deseasonalized[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
    "    results_values_deseasonalized[\"rsquared\"].append(rsquared*100)\n",
    "\n",
    "   #Log Raw Model\n",
    "    x_value = df['log_x_value']\n",
    "    y_value = df['log_y_value']\n",
    "    X = sm.add_constant(x_value)\n",
    "    model = sm.OLS(y_value, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    #(Null Hypothesis test) Coefficient with a p value less than 0.05\n",
    "#     if result.f_pvalue < 0.05:\n",
    "        \n",
    "    rsquared = result.rsquared\n",
    "    coefficient_pvalue = result.f_pvalue\n",
    "    intercept, slope = result.params\n",
    "    mean_price = np.mean(x_value)\n",
    "    mean_quantity = np.mean(y_value)\n",
    "    tintercept, t_score = result.tvalues\n",
    "\n",
    "    #Price elasticity Formula\n",
    "    price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
    "\n",
    "    #Append results into dictionary for dataframe\n",
    "    results_values_log_raw[\"name\"].append(column)\n",
    "    results_values_log_raw[\"price_elasticity\"].append(price_elasticity)\n",
    "    results_values_log_raw[\"price_mean\"].append(mean_price)\n",
    "    results_values_log_raw[\"quantity_mean\"].append(mean_quantity)\n",
    "    results_values_log_raw[\"intercept\"].append(intercept)\n",
    "    results_values_log_raw['t_score'].append(t_score)\n",
    "    results_values_log_raw[\"slope\"].append(slope)\n",
    "    results_values_log_raw[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
    "    results_values_log_raw[\"rsquared\"].append(rsquared*100)\n",
    "    \n",
    "    #log Detrended\n",
    "    x_value = df['log_x_value']\n",
    "    y_value = df['log_y_value_detrended']\n",
    "    X = sm.add_constant(x_value)\n",
    "    model = sm.OLS(y_value, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    #(Null Hypothesis test) Coefficient with a p value less than 0.05\n",
    "#     if result.f_pvalue < 0.05:\n",
    "        \n",
    "    rsquared = result.rsquared\n",
    "    coefficient_pvalue = result.f_pvalue\n",
    "    intercept, slope = result.params\n",
    "    mean_price = np.mean(x_value)\n",
    "    mean_quantity = np.mean(y_value)\n",
    "    tintercept, t_score = result.tvalues\n",
    "\n",
    "    #Price elasticity Formula\n",
    "    price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
    "\n",
    "    #Append results into dictionary for dataframe\n",
    "    results_values_log_detrended[\"name\"].append(column)\n",
    "    results_values_log_detrended[\"price_elasticity\"].append(price_elasticity)\n",
    "    results_values_log_detrended[\"price_mean\"].append(mean_price)\n",
    "    results_values_log_detrended[\"quantity_mean\"].append(mean_quantity)\n",
    "    results_values_log_detrended[\"intercept\"].append(intercept)\n",
    "    results_values_log_detrended['t_score'].append(t_score)\n",
    "    results_values_log_detrended[\"slope\"].append(slope)\n",
    "    results_values_log_detrended[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
    "    results_values_log_detrended[\"rsquared\"].append(rsquared*100)\n",
    "    \n",
    "    #log Deseasonalized Model\n",
    "    x_value = df['log_x_value']\n",
    "    y_value = df['log_y_value_deseasonalized']\n",
    "    X = sm.add_constant(x_value)\n",
    "    model = sm.OLS(y_value, X)\n",
    "    result = model.fit()\n",
    "    \n",
    "    #(Null Hypothesis test) Coefficient with a p value less than 0.05\n",
    "#     if result.f_pvalue < 0.05:\n",
    "        \n",
    "    rsquared = result.rsquared\n",
    "    coefficient_pvalue = result.f_pvalue\n",
    "    intercept, slope = result.params\n",
    "    mean_price = np.mean(x_value)\n",
    "    mean_quantity = np.mean(y_value)\n",
    "    tintercept, t_score = result.tvalues\n",
    "\n",
    "    #Price elasticity Formula\n",
    "    price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
    "\n",
    "    #Append results into dictionary for dataframe\n",
    "    results_values_log_deseasonalized[\"name\"].append(column)\n",
    "    results_values_log_deseasonalized[\"price_elasticity\"].append(price_elasticity)\n",
    "    results_values_log_deseasonalized[\"price_mean\"].append(mean_price)\n",
    "    results_values_log_deseasonalized[\"quantity_mean\"].append(mean_quantity)\n",
    "    results_values_log_deseasonalized[\"intercept\"].append(intercept)\n",
    "    results_values_log_deseasonalized['t_score'].append(t_score)\n",
    "    results_values_log_deseasonalized[\"slope\"].append(slope)\n",
    "    results_values_log_deseasonalized[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
    "    results_values_log_deseasonalized[\"rsquared\"].append(rsquared*100)\n",
    "    \n",
    "df_raw = pd.DataFrame.from_dict(results_values_raw)\n",
    "df_raw['ID'] = '1-Raw'\n",
    "df_raw_detrended = pd.DataFrame.from_dict(results_values_detrended)\n",
    "df_raw_detrended['ID'] = '5-Raw_Detrended'\n",
    "df_raw_deseasonalized = pd.DataFrame.from_dict(results_values_deseasonalized)\n",
    "df_raw_deseasonalized['ID'] = '6-results_values_deseasonalized'\n",
    "df_raw_log = pd.DataFrame.from_dict(results_values_log_raw)\n",
    "df_raw_log['ID'] = '4-Log_Raw'\n",
    "df_raw_detrended_log = pd.DataFrame.from_dict(results_values_log_detrended)\n",
    "df_raw_detrended_log['ID'] = '2-Log_Raw_Detrended'\n",
    "df_raw_deseasonalized_log = pd.DataFrame.from_dict(results_values_log_deseasonalized)\n",
    "df_raw_deseasonalized_log['ID'] = '3-Log_results_values_deseasonalized'\n",
    "final_df = pd.concat([df_raw,df_raw_detrended,df_raw_deseasonalized,df_raw_log,df_raw_detrended_log,df_raw_deseasonalized_log])\n",
    "df_elasticity =final_df[['ID','name','price_elasticity','t_score','coefficient_pvalue','slope','price_mean','quantity_mean','intercept','rsquared']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefe3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in x_values_mod.columns[1:]:\n",
    "#     column_points = []\n",
    "#     for i in range(len(x_values_mod[column])):\n",
    "#         if not np.isnan(x_values_mod[column][i]) and not np.isnan(y_values_mod[column][i]):\n",
    "#             column_points.append((x_values_mod[column][i], y_values_mod[column][i]))\n",
    "#     df = pd.DataFrame(list(column_points), columns= ['x_value', 'y_value'])\n",
    "#     sns.regplot(x=\"x_value\", y=\"y_value\", data=df, fit_reg=True)\n",
    "#     plt.xlabel('Price')\n",
    "#     plt.ylabel('Quantity')\n",
    "#     plt.show()\n",
    "\n",
    "#     #Linear Regression Model\n",
    "# #     x_value = df['x_value']\n",
    "# #     y_value = df['y_value']\n",
    "# #     X = sm.add_constant(x_value)\n",
    "# #     model_raw = sm.OLS(y_value, X)\n",
    "# #     result_raw = model_raw.fit()\n",
    "#     x_value = [i for i in range(0, len(df))]\n",
    "#     x_value = np.reshape(x_value, (len(x_value), 1))\n",
    "#     y_value = df.values\n",
    "#     model=LinearRegression()\n",
    "#     model.fit(x_value,y_value)\n",
    "#     # calculate trend\n",
    "#     trend = model.predict(x_value)\n",
    "#     # plot trend\n",
    "#     plt.plot(y_value)\n",
    "#     plt.plot(trend)\n",
    "#     plt.show()\n",
    "#     # detrend\n",
    "#     detrended = [y_value[i]-trend[i] for i in range(0, len(df))]\n",
    "#     # plot detrended\n",
    "#     plt.plot(detrended)\n",
    "#     plt.show()\n",
    "#     print(detrended)\n",
    "#     print(df)\n",
    "    \n",
    "#     #(Null Hypothesis test) Coefficient with a p value less than 0.05\n",
    "# #     if result.f_pvalue < 0.05:\n",
    "        \n",
    "# #     rsquared = result.rsquared\n",
    "# #     coefficient_pvalue = result.f_pvalue\n",
    "# #     intercept, slope = result.params\n",
    "# #     mean_price = np.mean(x_value)\n",
    "# #     mean_quantity = np.mean(y_value)\n",
    "# #     tintercept, t_score = result.tvalues\n",
    "\n",
    "# #     #Price elasticity Formula\n",
    "# #     price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
    "\n",
    "# #     #Append results into dictionary for dataframe\n",
    "# #     results_values[\"name\"].append(column)\n",
    "# #     results_values[\"price_elasticity\"].append(price_elasticity)\n",
    "# #     results_values[\"price_mean\"].append(mean_price)\n",
    "# #     results_values[\"quantity_mean\"].append(mean_quantity)\n",
    "# #     results_values[\"intercept\"].append(intercept)\n",
    "# #     results_values['t_score'].append(t_score)\n",
    "# #     results_values[\"slope\"].append(slope)\n",
    "# #     results_values[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
    "# #     results_values[\"rsquared\"].append(rsquared*100)\n",
    "        \n",
    "# # final_df = pd.DataFrame.from_dict(results_values)\n",
    "# # df_elasticity =final_df[['name','price_elasticity','t_score','coefficient_pvalue','slope','price_mean','quantity_mean','intercept','rsquared']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d34b4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.sort_values(by=['ID','name'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876b9ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "good=final_df[final_df['rsquared']>=30]\n",
    "good.sort_values(by='rsquared',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7daf98-c6d9-408d-8e71-0fe5f02b06b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"jay_test_excel_sku_R2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456495b5",
   "metadata": {},
   "source": [
    "## Log Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae3312c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LC=df_LC.drop('Sales',axis=1)\n",
    "df_LC.head()\n",
    "df_LC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a581816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LC_log=df_LC.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0075dbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LC_log['LogPrice'] = np.log(df_LC_log['Price'])\n",
    "df_LC_log['LogQty'] = np.log(df_LC_log['Qty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LC_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1724635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Prep using pivot\n",
    "x_pivot_log = df_LC_log.pivot(index= 'Year_Month' ,columns='LC' ,values='LogPrice')\n",
    "x_values_log = pd.DataFrame(x_pivot_log.to_records())\n",
    "print(x_values_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c13403",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing_x_log = x_values_log.isnull().sum() * 100 / len(x_values_log)\n",
    "missing_value_df_x_log = pd.DataFrame({'column_name': x_values_log.columns,\n",
    "                                 'percent_missing': percent_missing_x_log})\n",
    "missing_value_df_x_log.sort_values(by=['percent_missing'])\n",
    "mod_missing_value_df_x_log=missing_value_df_x_log[missing_value_df_x_log.percent_missing<=20]\n",
    "mod_missing_value_df_x_log\n",
    "mod_missing_value_df_x_log=mod_missing_value_df_x_log.reset_index(drop=True)\n",
    "mod_missing_value_df_x_log['column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dd0ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_values_mod_log = x_values_log[x_values_log.columns[x_values_log.columns.isin(mod_missing_value_df_x_log['column_name'].astype('str'))]]\n",
    "x_values_mod_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed79d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Prep using pivot\n",
    "y_pivot_log = df_LC_log.pivot(index= 'Year_Month' ,columns='LC' ,values='LogQty')\n",
    "y_values_log = pd.DataFrame(y_pivot_log.to_records())\n",
    "print(y_values_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9274ff4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing_y_log = y_values_log.isnull().sum() * 100 / len(y_values_log)\n",
    "missing_value_df_y_log = pd.DataFrame({'column_name': y_values_log.columns,\n",
    "                                 'percent_missing': percent_missing_y_log})\n",
    "# missing_value_df_y_log.sort_values(by=['percent_missing'])\n",
    "mod_missing_value_df_y_log=missing_value_df_y_log[missing_value_df_y_log.percent_missing<=20]\n",
    "# mod_missing_value_df_y_log\n",
    "mod_missing_value_df_y_log=mod_missing_value_df_y_log.reset_index(drop=True)\n",
    "mod_missing_value_df_y_log['column_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677343e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_values_mod_log = y_values_log[y_values_log.columns[y_values_log.columns.isin(mod_missing_value_df_y_log['column_name'].astype('str'))]]\n",
    "y_values_mod_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c349b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "points = []\n",
    "results_values_log = {\n",
    "    \"name\": [],\n",
    "    \"price_elasticity\": [],\n",
    "    \"price_mean\": [],\n",
    "    \"quantity_mean\": [],\n",
    "    \"intercept\": [],\n",
    "    \"t_score\":[],\n",
    "    \"slope\": [],\n",
    "    \"coefficient_pvalue\" : [],\n",
    "    \"rsquared\" : [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8730b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in x_values_mod_log.columns[1:]:\n",
    "    column_points = []\n",
    "    for i in range(len(x_values_mod_log[column])):\n",
    "        if not np.isnan(x_values_mod_log[column][i]) and not np.isnan(y_values_mod_log[column][i]):\n",
    "            column_points.append((x_values_mod_log[column][i], y_values_mod_log[column][i]))\n",
    "    df_log = pd.DataFrame(list(column_points), columns= ['x_value', 'y_value'])\n",
    "\n",
    "\n",
    "    #Linear Regression Model\n",
    "    x_value_log = df_log['x_value']\n",
    "    y_value_log = df_log['y_value']\n",
    "    X = sm.add_constant(x_value_log)\n",
    "    model_log = sm.OLS(y_value_log, X)\n",
    "    result_log = model_log.fit()\n",
    "    \n",
    "    \n",
    "    #(Null Hypothesis test) Coefficient with a p value less than 0.05\n",
    "#     if result.f_pvalue < 0.05:\n",
    "        \n",
    "    rsquared = result_log.rsquared\n",
    "    coefficient_pvalue = result_log.f_pvalue\n",
    "    intercept, slope = result_log.params\n",
    "    mean_price = np.mean(x_value_log)\n",
    "    mean_quantity = np.mean(y_value_log)\n",
    "    tintercept, t_score = result_log.tvalues\n",
    "\n",
    "    #Price elasticity Formula\n",
    "    price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
    "\n",
    "    #Append results into dictionary for dataframe\n",
    "    results_values_log[\"name\"].append(column)\n",
    "    results_values_log[\"price_elasticity\"].append(price_elasticity)\n",
    "    results_values_log[\"price_mean\"].append(mean_price)\n",
    "    results_values_log[\"quantity_mean\"].append(mean_quantity)\n",
    "    results_values_log[\"intercept\"].append(intercept)\n",
    "    results_values_log['t_score'].append(t_score)\n",
    "    results_values_log[\"slope\"].append(slope)\n",
    "    results_values_log[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
    "    results_values_log[\"rsquared\"].append(rsquared*100)\n",
    "        \n",
    "final_df_log = pd.DataFrame.from_dict(results_values_log)\n",
    "df_elasticity_log =final_df_log[['name','price_elasticity','t_score','coefficient_pvalue','slope','price_mean','quantity_mean','intercept','rsquared']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd5545",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_log.sort_values(by=['rsquared'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bc3acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_log=final_df_log[final_df_log['rsquared']>=30]\n",
    "good_log.sort_values(by='rsquared',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e51999-8183-4811-ac8f-d7ea56bb061c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv(\"C:\\\\Users\\\\bhasraya\\\\OneDrive - DRiV Inc\\\\MP\\\\Adhoc\\\\Strut Assemblies - Tom Galla/excel_lc.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0981d70-438e-4271-a07b-42314c0b8462",
   "metadata": {},
   "source": [
    "## Instrumental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0805b334-7893-400c-9f97-600c370c68ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "from linearmodels import IV2SLS\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6233bfb1-2ff6-4a24-b0f2-63f9e8a5690d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IV=pd.read_csv('Strut_Assemblies_Python.csv')\n",
    "df_IV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e52dcbe-bbba-4be7-9156-2c4ad89c7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IV['Day'] = \"1\"\n",
    "df_IV['Year']=df_IV['Year'].astype(str)\n",
    "df_IV['Month_Num']=df_IV['Month_Num'].astype(str)\n",
    "# df['Month1']=df['Month_Num']\n",
    "# df['Year_Month']=pd.to_datetime(df[[\"Year\", \"Month\", \"Day\"]])\n",
    "df_IV['Year_Month']=pd.to_datetime(df_IV.Year+df_IV.Month_Num+df_IV.Day, format=\"%Y%m%d\")\n",
    "df_IV.rename(columns={'Price':'Price'}, inplace=True)\n",
    "df_IV.rename(columns={'Units':'Qty'}, inplace=True)\n",
    "df_IV.rename(columns={'Part/Sku':'Material'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b212f5-1fb7-4396-94e3-12a32d3be8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IV.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9144a826-7926-43c3-88af-5539784c7773",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_IV=df_IV.dropna(axis=0, subset=('Price', ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c6bb83-f388-4796-ac11-917c32f9462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check values in different Life Cycle\n",
    "LC = df_IV['LC'].value_counts()\n",
    "print(\"LC Percentage\\n{}\\n{}\\n LC values count\\n{}\\n{}\".format(\n",
    "      50*\"-\", (LC / len(df_IV.index))[:5] * 100, 50*\"-\", LC[:5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c0f757-84a7-4e2a-9f1f-e48ecb56198f",
   "metadata": {},
   "source": [
    "## Data Exclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d46069-03a0-4349-9ef8-332066f2ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate the data\n",
    "df_LC=df_IV[(df_IV.Year_Month<'2022-08-01') & (df_IV.Year_Month>='2020-07-01')]\n",
    "# df_LC=df_IV.copy()\n",
    "df_LC = df_LC.groupby(['Year_Month','LC']).agg({'Sales':'sum','Qty': 'sum', 'Income': 'mean' }).reset_index()\n",
    "df_LC['Price']=df_LC['Sales']/df_LC['Qty']\n",
    "df_LC.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3a18f6-3f7d-4045-af7d-a249f9600b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LC['Price2'] = np.log(df_LC['Price'])\n",
    "df_LC['Qty2'] = np.log(df_LC['Qty'])\n",
    "df_LC['Income2'] = np.log(df_LC['Income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f28a03-faba-49f7-9f8a-cb0c98a9ebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean, Max, Min by LCs\n",
    "lcprices = df_LC.groupby('LC').agg({'Price' : ['mean', 'min', 'max']})\n",
    "lcprices.columns = ['lc_price_mean','lc_price_min', 'lc_price_max']\n",
    "lcprices[\"price_diff\"] = lcprices[\"lc_price_max\"] - lcprices[\"lc_price_min\"]\n",
    "lcprices = lcprices.reset_index()\n",
    "lcprices.sort_values(by=\"price_diff\", ascending = False, inplace = True)\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):  \n",
    "     print(lcprices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f343e95-e34b-490c-a029-bb36d507eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Box Plot\n",
    "pct_threshold = 99.0\n",
    "# censor below threshold\n",
    "pct95facet = np.percentile(df_LC['Price'], pct_threshold)\n",
    "\n",
    "box_dist = (\n",
    "    ggplot(df_LC) + \n",
    "    geom_boxplot(\n",
    "        aes(x = 'LC',\n",
    "            y = 'Price'), colour=\"#1F3552\", fill=\"#4271AE\", \n",
    "                   alpha=0.7,\n",
    "                   outlier_shape=\".\",\n",
    "                   outlier_colour=\"red\"       \n",
    "    ) +\n",
    "    labs(\n",
    "        title ='Strut Assemblies by LC',\n",
    "        x = 'LC',\n",
    "        y = 'Price',\n",
    "    ) +\n",
    "    scale_y_continuous() +\n",
    "    geom_hline(yintercept = pct95facet) + # add percentile solid line\n",
    "    theme(axis_text_x = element_text(angle = 45, hjust = 1)) + \n",
    "    theme(figure_size=(20, 12)) + \n",
    "    theme(text=element_text(family=\"Tahoma\", size=12)) +\n",
    "    theme(axis_text_x=element_text(colour=\"black\", size=12)) +\n",
    "    theme(axis_text_y=element_text(colour=\"black\", size=12))\n",
    ")\n",
    "box_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bed8a5-22c0-4a1a-9759-318e8fbdeab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Prep using pivot\n",
    "x_pivot = df_LC.pivot(index= 'Year_Month' ,columns='LC' ,values='Price')\n",
    "x_values = pd.DataFrame(x_pivot.to_records())\n",
    "print(x_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95b78e0-97f6-47dd-b8e6-a5aab929eaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_missing_x = x_values.isnull().sum() * 100 / len(x_values)\n",
    "missing_value_df_x = pd.DataFrame({'column_name': x_values.columns,\n",
    "                                 'percent_missing': percent_missing_x})\n",
    "print(missing_value_df_x.sort_values(by=['percent_missing']))\n",
    "mod_missing_value_df_x=missing_value_df_x[missing_value_df_x.percent_missing<=20]\n",
    "mod_missing_value_df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbcfb0d-547e-4f79-9939-bd8e86a3f78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_missing_value_df_x=mod_missing_value_df_x.reset_index(drop=True)\n",
    "x_values_mod = x_values[x_values.columns[x_values.columns.isin(mod_missing_value_df_x['column_name'].astype('str'))]]\n",
    "x_values_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf7accf-bea8-4d21-b0d6-a36f881ca788",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pivot = df_LC.pivot( index = 'Year_Month',columns='LC', values='Qty')\n",
    "y_values = pd.DataFrame(y_pivot.to_records())\n",
    "print(y_values)\n",
    "percent_missing_y = y_values.isnull().sum() * 100 / len(y_values)\n",
    "missing_value_df_y = pd.DataFrame({'column_name': y_values.columns,\n",
    "                                 'percent_missing': percent_missing_y})\n",
    "print(missing_value_df_y.sort_values(by=['percent_missing']))\n",
    "mod_missing_value_df_y=missing_value_df_y[missing_value_df_y.percent_missing<=20]\n",
    "mod_missing_value_df_y=mod_missing_value_df_y.reset_index(drop=True)\n",
    "y_values_mod = y_values[y_values.columns[y_values.columns.isin(mod_missing_value_df_y['column_name'].astype('str'))]]\n",
    "y_values_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e40d2-6f6c-4dbd-a094-22d3e47a2cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_pivot = df_LC.pivot( index = 'Year_Month',columns='LC', values='Income')\n",
    "z_values = pd.DataFrame(z_pivot.to_records())\n",
    "print(z_values)\n",
    "percent_missing_z = z_values.isnull().sum() * 100 / len(z_values)\n",
    "missing_value_df_z = pd.DataFrame({'column_name': z_values.columns,\n",
    "                                 'percent_missing': percent_missing_z})\n",
    "print(missing_value_df_z.sort_values(by=['percent_missing']))\n",
    "mod_missing_value_df_z=missing_value_df_z[missing_value_df_z.percent_missing<=20]\n",
    "mod_missing_value_df_z=mod_missing_value_df_z.reset_index(drop=True)\n",
    "z_values_mod = z_values[z_values.columns[z_values.columns.isin(mod_missing_value_df_z['column_name'].astype('str'))]]\n",
    "z_values_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5996c53-39e9-4ee0-97db-a59274b3d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = []\n",
    "results_values = {\n",
    "    \"name\": [],\n",
    "    \"price_elasticity\": [],\n",
    "    \"price_mean\": [],\n",
    "    \"quantity_mean\": [],\n",
    "    \"intercept\": [],\n",
    "    \"t_score\":[],\n",
    "    \"slope\": [],\n",
    "    \"coefficient_pvalue\" : [],\n",
    "    \"rsquared\" : [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5cbefd-3779-42f8-990e-5863ffba03f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in x_values_mod.columns[1:]:\n",
    "    column_points = []\n",
    "    for i in range(len(x_values_mod[column])):\n",
    "        if not np.isnan(x_values_mod[column][i]) and not np.isnan(y_values_mod[column][i]) and not np.isnan(z_values_mod[column][i]):\n",
    "            column_points.append((x_values_mod[column][i], y_values_mod[column][i], z_values_mod[column][i]))\n",
    "    df = pd.DataFrame(list(column_points), columns= ['x_value', 'y_value','z_value'])\n",
    "    sns.regplot(x=\"x_value\", y=\"y_value\", data=df, fit_reg=True)\n",
    "    plt.xlabel('Price')\n",
    "    plt.ylabel('Quantity')\n",
    "    plt.show()\n",
    "    sns.regplot(x=\"z_value\", y=\"y_value\", data=df, fit_reg=True)\n",
    "    plt.xlabel('Income')\n",
    "    plt.ylabel('Quantity')\n",
    "    plt.show()\n",
    "\n",
    "    #Linear Regression Model\n",
    "    # x_value = df['x_value']\n",
    "    # y_value = df['y_value']\n",
    "    # X = sm.add_constant(x_value)\n",
    "    # model = sm.OLS(y_value, X)\n",
    "    # result = model.fit()\n",
    "    \n",
    "    model = IV2SLS.from_formula(\"y_value ~ 1 + [x_value ~ z_value]\", df).fit()\n",
    "    result = model.summary\n",
    "    print(result)\n",
    "    \n",
    "    \n",
    "    #(Null Hypothesis test) Coefficient with a p value less than 0.05\n",
    "#     if result.f_pvalue < 0.05:\n",
    "        \n",
    "    rsquared = result.rsquared\n",
    "    coefficient_pvalue = result.f_pvalue\n",
    "    intercept, slope = result.params\n",
    "    mean_price = np.mean(x_value)\n",
    "    mean_quantity = np.mean(y_value)\n",
    "    tintercept, t_score = result.tvalues\n",
    "\n",
    "    #Price elasticity Formula\n",
    "    price_elasticity = (slope)*(mean_price/mean_quantity)    \n",
    "\n",
    "    #Append results into dictionary for dataframe\n",
    "    results_values[\"name\"].append(column)\n",
    "    results_values[\"price_elasticity\"].append(price_elasticity)\n",
    "    results_values[\"price_mean\"].append(mean_price)\n",
    "    results_values[\"quantity_mean\"].append(mean_quantity)\n",
    "    results_values[\"intercept\"].append(intercept)\n",
    "    results_values['t_score'].append(t_score)\n",
    "    results_values[\"slope\"].append(slope)\n",
    "    results_values[\"coefficient_pvalue\"].append(coefficient_pvalue)\n",
    "    results_values[\"rsquared\"].append(rsquared*100)\n",
    "        \n",
    "final_df = pd.DataFrame.from_dict(results_values)\n",
    "df_elasticity =final_df[['name','price_elasticity','t_score','coefficient_pvalue','slope','price_mean','quantity_mean','intercept','rsquared']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55051c02-4045-4685-ab90-fdb4f62e101b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
